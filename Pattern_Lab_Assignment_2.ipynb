{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pattern Lab Assignment 2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMcEjbGBG9AkoeHaQQ/0y6A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adnanbd/PatternLab/blob/master/Pattern_Lab_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtgcjOWN40YT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ff6ce00-5228-4e5d-d9f3-47454f1ffa8d"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLHSbiYi6hB-"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "data_files = sorted(glob.glob(\"/content/drive/My Drive/Study/Pattern Lab/iLearn-master/NPY/*.npy\"))\n",
        "#data_files = glob.glob(\"/content/drive/My Drive/Study/Pattern Lab/xyz/*.npy\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZdQ4YRDQeN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c4c64d-8f33-4436-fb63-3f8f0b11490a"
      },
      "source": [
        "data_file_NGsub_test = []\n",
        "data_file_NGsub_train = []\n",
        "data_file_PGsub_test = []\n",
        "data_file_PGsub_train = []\n",
        "\n",
        "for data_file in data_files:\n",
        "  file_info = data_file.split('/')\n",
        "  if file_info[-1].startswith(\"NGsub_test\"):\n",
        "    data_file_NGsub_test.append(data_file)\n",
        "  elif file_info[-1].startswith(\"NGsub_train\"):\n",
        "    data_file_NGsub_train.append(data_file)\n",
        "  elif file_info[-1].startswith(\"PGsub_test\"):\n",
        "    data_file_PGsub_test.append(data_file)\n",
        "  elif file_info[-1].startswith(\"PGsub_train\"):\n",
        "    data_file_PGsub_train.append(data_file)\n",
        "\n",
        "\n",
        "print(len(data_file_NGsub_test))\n",
        "print(len(data_file_NGsub_train))\n",
        "print(len(data_file_PGsub_test))\n",
        "print(len(data_file_PGsub_train))\n",
        "\n",
        "\n",
        "print(np.load(data_file_NGsub_test[1]).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "(59, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d5ltI81AzWj"
      },
      "source": [
        "# **NGsub_train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeIYpB2895d-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf3e1330-10cc-4a87-c718-557cae1febb0"
      },
      "source": [
        "\n",
        "index_NGsub_train = []\n",
        "\n",
        "split1 = data_file_NGsub_train[0].split(\"/\")\n",
        "split2 = split1[-1].split(\"_\")\n",
        "split3 = split2[-1].split(\".\")\n",
        "feature_name = split3[0]\n",
        "num_rows, num_cols = np.load(data_file_NGsub_train[0]).shape\n",
        "index_NGsub_train.append({\"Feature\":feature_name,\"start_index\":0,\"end_index\": int(num_cols)-1})\n",
        "temp = np.load(data_file_NGsub_train[0])\n",
        "i = 0\n",
        "\n",
        "for data_file in data_file_NGsub_train:\n",
        "  if i > 0:\n",
        "    results = np.load(data_file)\n",
        "    #print(results.shape)\n",
        "    #print(data_file)\n",
        "\n",
        "    split1 = data_file.split(\"/\")\n",
        "    split2 = split1[-1].split(\"_\")\n",
        "    split3 = split2[-1].split(\".\")\n",
        "    feature_name = split3[0]\n",
        "    num_rows, num_cols = np.load(data_file).shape\n",
        "    index_NGsub_train.append({\"Feature\":feature_name,\"start_index\":(index_NGsub_train[i-1][\"end_index\"] + 1),\"end_index\": (int(num_cols) + index_NGsub_train[i-1][\"end_index\"])})\n",
        "\n",
        "    temp = np.concatenate((temp,results),axis=1)\n",
        "  i = i+1\n",
        "\n",
        "print(temp.shape)\n",
        "\n",
        "print(*index_NGsub_train, sep = \"\\n\") \n",
        "#np.save(f\"/content/drive/My Drive/Study/Pattern Lab/temp/data_file_NGsub_train.npy\", temp)\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Study/Pattern Lab/temp/FeatureIndex.txt', 'w') as writefile:\n",
        "  for element in index_NGsub_train:\n",
        "    writefile.write(str(element) + \"#\")\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(844, 1302)\n",
            "{'Feature': 'ANF', 'start_index': 0, 'end_index': 40}\n",
            "{'Feature': 'gap1', 'start_index': 41, 'end_index': 72}\n",
            "{'Feature': 'gap3', 'start_index': 73, 'end_index': 136}\n",
            "{'Feature': 'gap5', 'start_index': 137, 'end_index': 232}\n",
            "{'Feature': 'gap7', 'start_index': 233, 'end_index': 360}\n",
            "{'Feature': 'lag7', 'start_index': 361, 'end_index': 402}\n",
            "{'Feature': 'EIIP', 'start_index': 403, 'end_index': 443}\n",
            "{'Feature': '10', 'start_index': 444, 'end_index': 571}\n",
            "{'Feature': '5', 'start_index': 572, 'end_index': 719}\n",
            "{'Feature': 'PseEIIP', 'start_index': 720, 'end_index': 783}\n",
            "{'Feature': 'lag7', 'start_index': 784, 'end_index': 797}\n",
            "{'Feature': 'binary', 'start_index': 798, 'end_index': 961}\n",
            "{'Feature': 'kmer1', 'start_index': 962, 'end_index': 965}\n",
            "{'Feature': 'kmer2', 'start_index': 966, 'end_index': 981}\n",
            "{'Feature': 'kmer3', 'start_index': 982, 'end_index': 1045}\n",
            "{'Feature': 'kmer4', 'start_index': 1046, 'end_index': 1301}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLVLFbbGg-6s"
      },
      "source": [
        "# **NGsub_test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yskpAVJNeP9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "789184a2-9621-4497-b34f-99e7e62e9012"
      },
      "source": [
        "index_NGsub_test = []\n",
        "\n",
        "split1 = data_file_NGsub_test[0].split(\"/\")\n",
        "split2 = split1[-1].split(\"_\")\n",
        "split3 = split2[-1].split(\".\")\n",
        "feature_name = split3[0]\n",
        "num_rows, num_cols = np.load(data_file_NGsub_test[0]).shape\n",
        "index_NGsub_test.append({\"Feature\":feature_name,\"start_index\":0,\"end_index\": int(num_cols)-1})\n",
        "temp = np.load(data_file_NGsub_test[0])\n",
        "i = 0\n",
        "for data_file in data_file_NGsub_test:\n",
        "  if i > 0:\n",
        "    results = np.load(data_file)\n",
        "    #print(results.shape)\n",
        "    #print(data_file)\n",
        "\n",
        "    split1 = data_file.split(\"/\")\n",
        "    split2 = split1[-1].split(\"_\")\n",
        "    split3 = split2[-1].split(\".\")\n",
        "    feature_name = split3[0]\n",
        "    num_rows, num_cols = np.load(data_file).shape\n",
        "    index_NGsub_test.append({\"Feature\":feature_name,\"start_index\":(index_NGsub_test[i-1][\"end_index\"] + 1),\"end_index\": (int(num_cols) + index_NGsub_test[i-1][\"end_index\"])})\n",
        "\n",
        "    temp = np.concatenate((temp,results),axis=1)\n",
        "  i = i+1\n",
        "\n",
        "print(temp.shape)\n",
        "\n",
        "print(*index_NGsub_test, sep = \"\\n\") \n",
        "#np.save(f\"/content/drive/My Drive/Study/Pattern Lab/temp/data_file_NGsub_test.npy\", temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(59, 1302)\n",
            "{'Feature': 'ANF', 'start_index': 0, 'end_index': 40}\n",
            "{'Feature': 'gap1', 'start_index': 41, 'end_index': 72}\n",
            "{'Feature': 'gap3', 'start_index': 73, 'end_index': 136}\n",
            "{'Feature': 'gap5', 'start_index': 137, 'end_index': 232}\n",
            "{'Feature': 'gap7', 'start_index': 233, 'end_index': 360}\n",
            "{'Feature': 'lag7', 'start_index': 361, 'end_index': 402}\n",
            "{'Feature': 'EIIP', 'start_index': 403, 'end_index': 443}\n",
            "{'Feature': '10', 'start_index': 444, 'end_index': 571}\n",
            "{'Feature': '5', 'start_index': 572, 'end_index': 719}\n",
            "{'Feature': 'PseEIIP', 'start_index': 720, 'end_index': 783}\n",
            "{'Feature': 'lag7', 'start_index': 784, 'end_index': 797}\n",
            "{'Feature': 'binary', 'start_index': 798, 'end_index': 961}\n",
            "{'Feature': 'kmer1', 'start_index': 962, 'end_index': 965}\n",
            "{'Feature': 'kmer2', 'start_index': 966, 'end_index': 981}\n",
            "{'Feature': 'kmer3', 'start_index': 982, 'end_index': 1045}\n",
            "{'Feature': 'kmer4', 'start_index': 1046, 'end_index': 1301}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOR3Zf7whCZr"
      },
      "source": [
        "# **PGsub_test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNb3_R23hDm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60601131-9c61-4248-afee-a96ab3554350"
      },
      "source": [
        "index_PGsub_test = []\n",
        "\n",
        "split1 = data_file_PGsub_test[0].split(\"/\")\n",
        "split2 = split1[-1].split(\"_\")\n",
        "split3 = split2[-1].split(\".\")\n",
        "feature_name = split3[0]\n",
        "num_rows, num_cols = np.load(data_file_PGsub_test[0]).shape\n",
        "index_PGsub_test.append({\"Feature\":feature_name,\"start_index\":0,\"end_index\": int(num_cols)-1})\n",
        "temp = np.load(data_file_PGsub_test[0])\n",
        "i = 0\n",
        "for data_file in data_file_PGsub_test:\n",
        "  if i > 0:\n",
        "    results = np.load(data_file)\n",
        "    #print(results.shape)\n",
        "    #print(data_file)\n",
        "\n",
        "    split1 = data_file.split(\"/\")\n",
        "    split2 = split1[-1].split(\"_\")\n",
        "    split3 = split2[-1].split(\".\")\n",
        "    feature_name = split3[0]\n",
        "    num_rows, num_cols = np.load(data_file).shape\n",
        "    index_PGsub_test.append({\"Feature\":feature_name,\"start_index\":(index_PGsub_test[i-1][\"end_index\"] + 1),\"end_index\": (int(num_cols) + index_PGsub_test[i-1][\"end_index\"])})\n",
        "\n",
        "    temp = np.concatenate((temp,results),axis=1)\n",
        "  i = i+1\n",
        "\n",
        "print(temp.shape)\n",
        "\n",
        "print(*index_PGsub_test, sep = \"\\n\") \n",
        "#np.save(f\"/content/drive/My Drive/Study/Pattern Lab/temp/data_file_PGsub_test.npy\", temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(59, 1302)\n",
            "{'Feature': 'ANF', 'start_index': 0, 'end_index': 40}\n",
            "{'Feature': 'gap1', 'start_index': 41, 'end_index': 72}\n",
            "{'Feature': 'gap3', 'start_index': 73, 'end_index': 136}\n",
            "{'Feature': 'gap5', 'start_index': 137, 'end_index': 232}\n",
            "{'Feature': 'gap7', 'start_index': 233, 'end_index': 360}\n",
            "{'Feature': 'lag7', 'start_index': 361, 'end_index': 402}\n",
            "{'Feature': 'EIIP', 'start_index': 403, 'end_index': 443}\n",
            "{'Feature': '10', 'start_index': 444, 'end_index': 571}\n",
            "{'Feature': '5', 'start_index': 572, 'end_index': 719}\n",
            "{'Feature': 'PseEIIP', 'start_index': 720, 'end_index': 783}\n",
            "{'Feature': 'lag7', 'start_index': 784, 'end_index': 797}\n",
            "{'Feature': 'binary', 'start_index': 798, 'end_index': 961}\n",
            "{'Feature': 'kmer1', 'start_index': 962, 'end_index': 965}\n",
            "{'Feature': 'kmer2', 'start_index': 966, 'end_index': 981}\n",
            "{'Feature': 'kmer3', 'start_index': 982, 'end_index': 1045}\n",
            "{'Feature': 'kmer4', 'start_index': 1046, 'end_index': 1301}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeGmoooXhEab"
      },
      "source": [
        "# **PGsub_train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJrhgzC_hFAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f92abaf-46c3-48d8-cf5a-05e67d4ceac1"
      },
      "source": [
        "index_PGsub_train = []\n",
        "\n",
        "split1 = data_file_PGsub_train[0].split(\"/\")\n",
        "split2 = split1[-1].split(\"_\")\n",
        "split3 = split2[-1].split(\".\")\n",
        "feature_name = split3[0]\n",
        "num_rows, num_cols = np.load(data_file_PGsub_train[0]).shape\n",
        "index_PGsub_train.append({\"Feature\":feature_name,\"start_index\":0,\"end_index\": int(num_cols)-1})\n",
        "temp = np.load(data_file_PGsub_train[0])\n",
        "i = 0\n",
        "for data_file in data_file_PGsub_train:\n",
        "  if i > 0:\n",
        "    results = np.load(data_file)\n",
        "    #print(results.shape)\n",
        "    #print(data_file)\n",
        "\n",
        "    split1 = data_file.split(\"/\")\n",
        "    split2 = split1[-1].split(\"_\")\n",
        "    split3 = split2[-1].split(\".\")\n",
        "    feature_name = split3[0]\n",
        "    num_rows, num_cols = np.load(data_file).shape\n",
        "    index_PGsub_train.append({\"Feature\":feature_name,\"start_index\":(index_PGsub_train[i-1][\"end_index\"] + 1),\"end_index\": (int(num_cols) + index_PGsub_train[i-1][\"end_index\"])})\n",
        "\n",
        "    temp = np.concatenate((temp,results),axis=1)\n",
        "  i = i+1\n",
        "\n",
        "print(temp.shape)\n",
        "\n",
        "print(*index_PGsub_train, sep = \"\\n\") \n",
        "#np.save(f\"/content/drive/My Drive/Study/Pattern Lab/temp/data_file_PGsub_train.npy\", temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(844, 1302)\n",
            "{'Feature': 'ANF', 'start_index': 0, 'end_index': 40}\n",
            "{'Feature': 'gap1', 'start_index': 41, 'end_index': 72}\n",
            "{'Feature': 'gap3', 'start_index': 73, 'end_index': 136}\n",
            "{'Feature': 'gap5', 'start_index': 137, 'end_index': 232}\n",
            "{'Feature': 'gap7', 'start_index': 233, 'end_index': 360}\n",
            "{'Feature': 'lag7', 'start_index': 361, 'end_index': 402}\n",
            "{'Feature': 'EIIP', 'start_index': 403, 'end_index': 443}\n",
            "{'Feature': '10', 'start_index': 444, 'end_index': 571}\n",
            "{'Feature': '5', 'start_index': 572, 'end_index': 719}\n",
            "{'Feature': 'PseEIIP', 'start_index': 720, 'end_index': 783}\n",
            "{'Feature': 'lag7', 'start_index': 784, 'end_index': 797}\n",
            "{'Feature': 'binary', 'start_index': 798, 'end_index': 961}\n",
            "{'Feature': 'kmer1', 'start_index': 962, 'end_index': 965}\n",
            "{'Feature': 'kmer2', 'start_index': 966, 'end_index': 981}\n",
            "{'Feature': 'kmer3', 'start_index': 982, 'end_index': 1045}\n",
            "{'Feature': 'kmer4', 'start_index': 1046, 'end_index': 1301}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs7kZUyFerAT"
      },
      "source": [
        "data_files_final = glob.glob(\"/content/drive/My Drive/Study/Pattern Lab/temp/*.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be_X-m2jjiFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433378e7-c62c-4983-e8ea-6a92434d0d0a"
      },
      "source": [
        "data_file_Gsub_test = []\n",
        "data_file_Gsub_train = []\n",
        "\n",
        "\n",
        "for data_file in data_files_final:\n",
        "  print(data_file)\n",
        "  file_info = data_file.split('/')\n",
        "  file_name = file_info[-1].split('_')\n",
        "  if file_name[3].startswith(\"train\"):\n",
        "    data_file_Gsub_train.append(data_file)\n",
        "  if file_name[3].startswith(\"test\"):\n",
        "    data_file_Gsub_test.append(data_file)\n",
        "\n",
        "print(len(data_file_Gsub_test))\n",
        "print(len(data_file_Gsub_train))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Study/Pattern Lab/temp/data_file_NGsub_train.npy\n",
            "/content/drive/My Drive/Study/Pattern Lab/temp/data_file_NGsub_test.npy\n",
            "/content/drive/My Drive/Study/Pattern Lab/temp/data_file_PGsub_test.npy\n",
            "/content/drive/My Drive/Study/Pattern Lab/temp/data_file_PGsub_train.npy\n",
            "2\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFJjLXU49kIE"
      },
      "source": [
        "# **Gsub_x_test & Gsub_y_test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSIpPgSUppuu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae93181-276f-46e0-f7e1-9771a0f98868"
      },
      "source": [
        "print(np.load(data_file_Gsub_test[0]).shape)\n",
        "print(np.load(data_file_Gsub_test[1]).shape)\n",
        "\n",
        "print(data_file_Gsub_test[0])\n",
        "print(data_file_Gsub_test[1])\n",
        "\n",
        "Gsub_test_y = []\n",
        "\n",
        "num_rows, num_cols = np.load(data_file_Gsub_test[0]).shape\n",
        "\n",
        "\n",
        "split1 = data_file_Gsub_test[0].split(\"/\")\n",
        "split2 = split1[-1].split(\"_\")\n",
        "i=0\n",
        "if split2[-2].startswith(\"N\"):\n",
        "  while i < int(num_rows):\n",
        "    Gsub_test_y.append(0)\n",
        "    i = i+1\n",
        "  while i < int(num_rows)*2:\n",
        "    Gsub_test_y.append(1)\n",
        "    i = i+1\n",
        "else:\n",
        "  while i < int(num_rows):\n",
        "    Gsub_test_y.append(1)\n",
        "    i = i+1\n",
        "  while i < int(num_rows)*2:\n",
        "    Gsub_test_y.append(0)\n",
        "    i = i+1\n",
        "\n",
        "\n",
        "Gsub_y_test = np.array(Gsub_test_y)\n",
        "Gsub_test = np.concatenate((np.load(data_file_Gsub_test[0]), np.load(data_file_Gsub_test[1])))\n",
        "\n",
        "print(Gsub_test.shape)\n",
        "print(Gsub_y_test.shape)\n",
        "\n",
        "\n",
        "##===================================================\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(59, 1302)\n",
            "(59, 1302)\n",
            "/content/drive/My Drive/Study/Pattern Lab/temp/data_file_NGsub_test.npy\n",
            "/content/drive/My Drive/Study/Pattern Lab/temp/data_file_PGsub_test.npy\n",
            "(118, 1302)\n",
            "(118,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLcQpsx-9tPq"
      },
      "source": [
        "# **Gsub_x_train & Gsub_y_train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWe0nGDE7gRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d54244b-85c2-4b6c-9db4-b9265dcd2c69"
      },
      "source": [
        "print(np.load(data_file_Gsub_train[0]).shape)\n",
        "print(np.load(data_file_Gsub_train[1]).shape)\n",
        "\n",
        "print(data_file_Gsub_train[0])\n",
        "print(data_file_Gsub_train[1])\n",
        "\n",
        "Gsub_train_y = []\n",
        "\n",
        "num_rows, num_cols = np.load(data_file_Gsub_train[0]).shape\n",
        "\n",
        "\n",
        "split1 = data_file_Gsub_train[0].split(\"/\")\n",
        "split2 = split1[-1].split(\"_\")\n",
        "i=0\n",
        "if split2[-2].startswith(\"N\"):\n",
        "  while i < int(num_rows):\n",
        "    Gsub_train_y.append(0)\n",
        "    i = i+1\n",
        "  while i < int(num_rows)*2:\n",
        "    Gsub_train_y.append(1)\n",
        "    i = i+1\n",
        "else:\n",
        "  while i < int(num_rows):\n",
        "    Gsub_train_y.append(1)\n",
        "    i = i+1\n",
        "  while i < int(num_rows)*2:\n",
        "    Gsub_train_y.append(0)\n",
        "    i = i+1\n",
        "\n",
        "\n",
        "Gsub_y_train = np.array(Gsub_train_y)\n",
        "Gsub_train = np.concatenate((np.load(data_file_Gsub_train[0]), np.load(data_file_Gsub_train[1])))\n",
        "\n",
        "print(Gsub_train.shape)\n",
        "print(Gsub_y_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(844, 1302)\n",
            "(844, 1302)\n",
            "/content/drive/My Drive/Study/Pattern Lab/temp/data_file_NGsub_train.npy\n",
            "/content/drive/My Drive/Study/Pattern Lab/temp/data_file_PGsub_train.npy\n",
            "(1688, 1302)\n",
            "(1688,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNhs5Emt8BWK"
      },
      "source": [
        "#np.save(f\"/content/drive/My Drive/Study/Pattern Lab/temp1/Gsub_x_train.npy\", Gsub_train)\n",
        "np.save(f\"/content/drive/My Drive/Study/Pattern Lab/temp1/Gsub_y_train.npy\", Gsub_y_train)\n",
        "#np.save(f\"/content/drive/My Drive/Study/Pattern Lab/temp1/Gsub_x_test.npy\", Gsub_test)\n",
        "np.save(f\"/content/drive/My Drive/Study/Pattern Lab/temp1/Gsub_y_test.npy\", Gsub_y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}